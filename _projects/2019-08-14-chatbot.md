---
layout: post
title: Topic-aware chatbot using RNN and NMF
description: ""
thumbnail: "/assets/images/projects/chatbot/architecture.png"
mathjax: true
---

 
This past summer I was fortunate enough to be accepted to a Research Experience for Undergraduates (REU) program hosted by the mathematics department of the University of California, Los Angeles. It was my first time doing research at a scale larger than projects for classes, and certainly the most time I have invested into any one project. My team worked full time for two months of the summer learning about and experimenting with new strategies for designing chatbots. For those who are not familiar, you can think of a chatbot as a computer program which you can have a conversation with; in other words, it is like texting with someone except the other person is the computer. Our specific research goal was to create a general-purpose chatbot which provides topical responses more so than general ones. For example, if you ask it something about basketball, it should in turn respond with something at least related to basketball, instead of just giving a generic response. As one can imagine, this is a very challenging and daunting task, but it would also be an extremely useful one to solve. People outside of academia are focused on this problem too, with OpenAI (a research laboratory based in San Francisco) currently having one of the best performing solutions with their GPT2 model. While OpenAI and similar companies have nearly unlimited brainpower as well as computing power, our resources were limited. Because of this, we did not set out to expand on the state of the art models, but instead focus on building off of slightly older (~ 2 years old) methods which are more reasonable in their cost to train.

## Team organization

Our project had the two components of text generation and topic modeling, so our team split into two groups which each focused on one part of the task. The idea was that we would work separately for the first half of project, learning all we can about the part of the problem we want to solve, developing individual models which perform well, and then in the second month we would combine these two concepts together into one coherent model. 

## Topic modeling
I was on the topic modeling team, and our advisor decided that we would use non-negative matrix factorization (NMF) instead of other methods. None of us had experience with NMF so we began by teaching ourselves about topic modeling in general, and then read about the specifics of NMF. The key aspect of NMF that gives it advantages over other methods is that both the original matrix and its two factor matrices which are produced contain only non-negative entries. This makes the topics that are extracted by the method much more interpretable than topics extracted from other methods. Other methods have negative entries as well, which means that topics can be "added" together but also "subtracted" from each other. When topics are combined in ways other than additive methods, the individual topics are generally less interpretable because the "difference" of two topics can represent something else. We can call these two matrices the dictionary matrix and the code matrix, and their product should approximate the original data matrix.

$$\texttt{Data} \approx \texttt{Dictionary} \times \texttt{Code}$$

If we perform NMF on an entire corpus, we can obtain the dictionary matrix for that corpus. The columns of this matrix represent the topics of the corpus. 
